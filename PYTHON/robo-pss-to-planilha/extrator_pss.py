import pdfplumber
import pandas as pd
import re
from datetime import datetime
import os

def extract_text_from_pdf(pdf_path):
    text = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    lines = page_text.split("\n")
                    possible_footer_keywords = [r'\bTel\b', r'\bFax\b', r'\bCEP\b', r'Rodovia', r'Km\s*\d+']
                    
                    num_lines_to_check = 4
                    lines_to_remove = 0
                    for i in range(1, num_lines_to_check + 1):
                        if len(lines) >= i:
                            line_to_check = lines[-i]
                            if any(re.search(keyword, line_to_check, re.IGNORECASE) for keyword in possible_footer_keywords):
                                lines_to_remove = i
                    
                    if lines_to_remove > 0:
                        lines = lines[:-lines_to_remove]

                    text += "\n".join(lines) + "\n"
    except Exception as e:
        print(f"Erro ao ler o PDF {os.path.basename(pdf_path)}: {e}")
    return text

def extract_info_from_text(text, filename):
    data = []

    disciplinas_comuns = sorted(list(set([
        "Matem√°tica", "L√≠ngua Portuguesa", "Hist√≥ria", "Geografia", "Educa√ß√£o F√≠sica",
        "Ci√™ncias", "Biologia", "Qu√≠mica", "F√≠sica", "Sociologia", "Filosofia",
        "Artes", "Ingl√™s", "Espanhol", "Educa√ß√£o Art√≠stica", "Ensino Religioso",
        "Inform√°tica", "Agropecu√°ria", "Zootecnia", "Enfermagem", "Contabilidade",
        "Administra√ß√£o", "Direito", "Pedagogia", "Letras", "Educa√ß√£o Especial",
        "Ci√™ncias Agr√°rias", "Tecnologias", "Educa√ß√£o do Campo", "EJA CAMPO",
        "Acompanhante Especializado", "Int√©rprete de Libras", "Merendeira", "SOME",
        "Contador", "Professor", "Qualquer disciplina", "Educa√ß√£o Geral", "L√≠ngua Inglesa",
        "Apoio - Tradutor Int√©rprete de Libras", "Atendimento Educacional Especializado", "AEE",
        "Brailista", "Ci√™ncias da Natureza e suas Tecnologias", "Ci√™ncias Humanas e suas Tecnologias",
        "Linguagens C√≥digos e suas Tecnologias", "Professor Coordenador(a) de Turma", "Projeto SEI"
    ])))
    
    municipios_comuns = sorted(list(set([
        "Abel Figueiredo", "Acar√°", "Afu√°", "√Ågua Azul do Norte", "Alenquer", "Almeirim", "Altamira",
        "Anaj√°s", "Ananindeua", "Anapu", "Augusto Corr√™a", "Aurora do Par√°", "Aveiro", "Bagre",
        "Bai√£o", "Bannach", "Barcarena", "Bel√©m", "Belterra", "Benevides", "Bom Jesus do Tocantins",
        "Bonito", "Bragan√ßa", "Brasil Novo", "Brejo Grande do Araguaia", "Breu Branco", "Buarque",
        "Cachoeira do Arari", "Cachoeira do Piri√°", "Camet√°", "Cana√£ dos Caraj√°s", "Capanema",
        "Capit√£o Po√ßo", "Castanhal", "Chaves", "Colares", "Concei√ß√£o do Araguaia", "Conc√≥rdia do Par√°",
        "Cumaru do Norte", "Curu√°", "Curu√ß√°", "Curion√≥polis", "Curralinho", "Dom Eliseu",
        "Eldorado dos Caraj√°s", "Faro", "Floresta do Araguaia", "Garraf√£o do Norte", "Goian√©sia do Par√°",
        "Gurup√°", "Icoaraci", "Igarap√©-A√ßu", "Igarap√©-Miri", "Inhangapi", "Ipixuna do Par√°", "Irituia",
        "Itaituba", "Itupiranga", "Jacareacanga", "Jacund√°", "Juruti", "Limoeiro do Ajuru",
        "M√£e do Rio", "Magalh√£es Barata", "Marab√°", "Maracan√£", "Marapanim", "Marituba",
        "Medicil√¢ndia", "Melga√ßo", "Mocajuba", "Moju", "Moju√≠ dos Campos", "Monte Alegre", "Muan√°",
        "Nova Esperan√ßa do Piri√°", "Nova Ipixuna", "Nova Timboteua", "Novo Progresso", "Novo Repartimento",
        "√ìbidos", "Oeiras do Par√°", "Our√©m", "Ouril√¢ndia do Norte", "Pacaj√°", "Palestina do Par√°",
        "Paragominas", "Parauapebas", "Pau D\'Arco", "Peixe-Boi", "Pi√ßarra", "Placas", "Ponta de Pedras",
        "Portel", "Porto de Moz", "Prainha", "Primavera", "Quatipuru", "Reden√ß√£o", "Rio Maria",
        "Rondon do Par√°", "Rur√≥polis", "Salin√≥polis", "Salvaterra", "Santa B√°rbara do Par√°",
        "Santa Cruz do Arari", "Santa Izabel do Par√°", "Santa Luzia do Par√°", "Santa Maria das Barreiras",
        "Santa Maria do Par√°", "Santana do Araguaia", "Santar√©m", "Santar√©m Novo", "Santo Ant√¥nio do Tau√°",
        "S√£o Caetano de Odivelas", "S√£o Domingos do Araguaia", "S√£o Domingos do Capim",
        "S√£o F√©lix do Xingu", "S√£o Francisco do Par√°", "S√£o Geraldo do Araguaia", "S√£o Jo√£o da Ponta",
        "S√£o Jo√£o de Pirabas", "S√£o Jo√£o do Araguaia", "S√£o Miguel do Guam√°", "S√£o Sebasti√£o da Boa Vista",
        "Sapucaia", "Senador Jos√© Porf√≠rio", "Soure", "Tail√¢ndia", "Terra Alta", "Terra Santa",
        "Tom√©-A√ßu", "Tracuateua", "Trair√£o", "Tucum√£", "Tucuru√≠", "Ulian√≥polis", "Uruar√°", "Vigia",
        "Viseu", "Vit√≥ria do Xingu", "Xinguara", "Anexo Estrela do Par√°", "Bela Vista do Baixo",
        "Bela Vista do Moco√µes", "Cachoeira da Serra", "Casa de T√°bua", "Castelo dos Sonhos",
        "Comunidade Arrozal", "Comunidade do Ipanema", "Comunidade Maria Ribeira",
        "Comunidade Nossa Senhora de Nazar√©", "Comunidade Porto Alegre", "Comunidade Santa Luzia",
        "Comunidade S√£o Francisco", "Comunidade S√£o Jos√©", "Comunidade S√£o Pedro",
        "Distrito de Moraes Almeida", "Distrito de Mosqueiro", "Estrela do Par√°", "Forquilha",
        "Mata Verde", "Santa Maria de Icatu", "Tabatinga", "Vila Bela Vista", "Vila do Carmo",
        "Vila Estrela do Par√°", "Vila Lawton", "Vila Martins Ferreira", "Vila Nazar√©", "Vila Nova",
        "Vila Ponta de Pedras", "Vila Romaria", "Vila Santa Cruz"
    ])))

    pss = "N/A"
    year = "N/A"

    pss_match = re.search(r'PSS\s*(?:N¬∫)?\s*(\d{2,4}/\d{4})', text, re.IGNORECASE) or \
                re.search(r'PROCESSO SELETIVO SIMPLIFICADO\s*(?:N¬∫)?\s*(\d{2,4}/\d{4})', text, re.IGNORECASE)
    if pss_match:
        pss = pss_match.group(1)

    date_match = re.search(r'Bel√©m,\s*\d{1,2}\s+de\s+\w+\s+de\s+(\d{4})', text, re.IGNORECASE)
    if date_match:
        year = date_match.group(1)
    else:
        year_match_in_edital = re.search(r'EDITAL\s*(?:n¬∫)?\s*\d{1,3}/(\d{4})', text, re.IGNORECASE)
        if year_match_in_edital:
            year = year_match_in_edital.group(1)
        else:
            valid_years = "|".join(map(str, range(2019, 2026)))
            fallback_match = re.search(r'\b(' + valid_years + r')\b', text + " " + filename)
            if fallback_match:
                year = fallback_match.group(1)

    def find_entries(text_to_search):
        municipalities = {mun for mun in municipios_comuns if re.search(r'\b' + re.escape(mun) + r'\b', text_to_search, re.IGNORECASE)}
        disciplines = {disc for disc in disciplinas_comuns if re.search(r'\b' + re.escape(disc) + r'\b', text_to_search, re.IGNORECASE)}
        return municipalities, disciplines

    quadro_vagas_match = re.search(r'QUADRO DE VAGAS(.*?)(?:TOTAL DE VAGAS|RELA√á√ÉO DE E-MAIL|Tiago Lima e Silva)', text, re.DOTALL | re.IGNORECASE)
    
    found_municipalities, found_disciplines = set(), set()
    if quadro_vagas_match:
        quadro_text = quadro_vagas_match.group(1)
        found_municipalities, found_disciplines = find_entries(quadro_text)

    if not found_municipalities and not found_disciplines:
        found_municipalities, found_disciplines = find_entries(text)

    final_municipalities = list(found_municipalities) if found_municipalities else ["N/A"]
    final_disciplines = list(found_disciplines) if found_disciplines else ["N/A"]

    for m in final_municipalities:
        for d in final_disciplines:
            data.append({
                "Ano": year,
                "PSS": pss,
                "Edital": filename.replace('.pdf', ''),
                "Munic√≠pio": m,
                "Disciplina": d,
                "Arquivo_Origem": filename,
                "Data_Extra√ß√£o": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            })

    return data

PASTA_PDFS = "C:/Users/SEDUC/Desktop/conv especiais"
ARQUIVO_SAIDA = "convocacoes_especiais.xlsx"

all_data = []

if not os.path.isdir(PASTA_PDFS):
    print(f" Erro: A pasta \033[91m'{PASTA_PDFS}'\033[0m n√£o foi encontrada.")
else:
    pdf_files = [f for f in os.listdir(PASTA_PDFS) if f.lower().endswith(".pdf")]
    
    if not pdf_files:
        print(f"Nenhum arquivo PDF encontrado em \033[93m'{PASTA_PDFS}'\033[0m.")
    else:
        for arquivo in pdf_files:
            caminho = os.path.join(PASTA_PDFS, arquivo)
            print(f"\033[94müìÑ Processando:\033[0m {arquivo}")

            texto_pdf = extract_text_from_pdf(caminho)
            
            if not texto_pdf:
                print(f"   -> \033[91mN√£o foi poss√≠vel extrair texto deste PDF.\033[0m\n")
                continue

            extracted_data = extract_info_from_text(texto_pdf, arquivo)
            
            if extracted_data:
                all_data.extend(extracted_data)
                print(f"   -> \033[92m‚úÖ {len(extracted_data)} registros extra√≠dos.\033[0m\n")
            else:
                print(f"   -> \033[93mNenhum dado relevante encontrado.\033[0m\n")

if all_data:
    df = pd.DataFrame(all_data)
    df.drop_duplicates(subset=["Ano", "PSS", "Edital", "Munic√≠pio", "Disciplina"], inplace=True)
    df.to_excel(ARQUIVO_SAIDA, index=False)
    print(f"\033[92mExtra√ß√£o conclu√≠da! {len(df)} registros √∫nicos salvos em {ARQUIVO_SAIDA}\033[0m")
else:
    print("\033[91m‚ùå Nenhuma informa√ß√£o foi extra√≠da de nenhum dos PDFs.\033[0m")
