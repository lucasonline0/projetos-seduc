import pdfplumber
import pandas as pd
import re
from datetime import datetime
import os

def extract_text_from_pdf(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        text = "\n".join([page.extract_text() for page in pdf.pages if page.extract_text()])
    return text

def extract_info_from_text(text, filename):
    data = []

    disciplinas_comuns = [
        "Matem√°tica", "L√≠ngua Portuguesa", "Hist√≥ria", "Geografia", "Educa√ß√£o F√≠sica",
        "Ci√™ncias", "Biologia", "Qu√≠mica", "F√≠sica", "Sociologia", "Filosofia",
        "Artes", "Ingl√™s", "Espanhol", "Educa√ß√£o Art√≠stica", "Ensino Religioso",
        "Inform√°tica", "Agropecu√°ria", "Zootecnia", "Enfermagem", "Contabilidade",
        "Administra√ß√£o", "Direito", "Pedagogia", "Letras", "Educa√ß√£o Especial",
        "Ci√™ncias Agr√°rias", "Tecnologias", "Educa√ß√£o do Campo", "EJA CAMPO",
        "Acompanhamento Especializado", "Int√©rprete de Libras", "Merendeira", "SOME",
        "Contador", "Professor"
    ]
    
    municipios_comuns = [
        "Bel√©m", "Ananindeua", "Santar√©m", "Castanhal", "Marab√°", "Parauapebas",
        "Altamira", "Reden√ß√£o", "Paragominas", "Tucuru√≠", "Barcarena", "Abaetetuba",
        "Camet√°", "Bragan√ßa", "Capanema", "Itaituba", "Marituba", "S√£o F√©lix do Xingu",
        "Xinguara", "Tail√¢ndia", "Breves", "Portel", "Vigia", "Salin√≥polis",
        "Benevides", "Santa Izabel do Par√°", "Capit√£o Po√ßo", "Monte Alegre",
        "Oriximin√°", "Dom Eliseu", "Ulian√≥polis", "Jacund√°", "Tom√©-A√ßu", "Concei√ß√£o do Araguaia",
        "Cumaru do Norte", "Floresta do Araguaia", "Pau D\"Arco", "Santa Maria das Barreiras",
        "Santana do Araguaia", "M√£e do Rio", "Aurora do Par√°", "Ipixuna do Par√°",
        "Jacareacanga", "Novo Progresso", "Placas", "Rur√≥polis", "Trair√£o", "Curralinho",
        "Bagre", "Chaves", "Melga√ßo", "Gurup√°", "Almeirim", "Medicil√¢ndia", "Porto de Moz",
        "Senador Jos√© Porf√≠rio", "Uruar√°", "Vit√≥ria do Xingu", "Goian√©sia do Par√°",
        "Novo Repartimento", "Pacaj√°", "Curua", "Faro", "Juruti", "Terra Santa",
        "Brasil Novo", "Anapu", "S√£o Miguel do Guam√°", "S√£o Jo√£o da Ponta", "S√£o Francisco do Par√°",
        "S√£o Domingos do Capim", "Santa Maria do Par√°", "Marapanim", "Inhangapi", "Curu√ß√°",
        "S√£o Caetano de Odivelas", "Santo Ant√¥nio do Tau√°", "Santa Luzia do Par√°",
        "Bonito", "Nova Timboteua", "Our√©m", "Peixe-Boi", "Primavera", "Quatipuru",
        "S√£o Jo√£o de Pirabas", "Augusto Corr√™a", "Cachoeira do Arari", "Colares", "Mocajuba",
        "Moj√∫", "Nova Esperan√ßa do Piri√°", "Oeiras do Par√°", "Ponta de Pedras", "S√£o Sebasti√£o da Boa Vista",
        "Soure", "Viseu", "Acar√°", "Afu√°", "√Ågua Azul do Norte", "Alenquer", "Anaj√°s", "Aveiro",
        "Bai√£o", "Bannach", "Belterra", "Bom Jesus do Tocantins", "Bonito", "Buarque", "Cachoeira do Piri√°",
        "Cana√£ dos Caraj√°s", "Cana√£ dos Caraj√°s", "Capanema", "Castelo dos Sonhos", "Chaves",
        "Colares", "Concei√ß√£o do Araguaia", "Conc√≥rdia do Par√°", "Curu√°", "Curion√≥polis",
        "Curralinho", "Garraf√£o do Norte", "Goian√©sia do Par√°", "Gurup√°", "Igarap√©-A√ßu",
        "Igarap√©-Miri", "Inhangapi", "Ipixuna do Par√°", "Irituia", "Itupiranga", "Jacareacanga",
        "Jacund√°", "Juruti", "Limoeiro do Ajuru", "Magalh√£es Barata", "Maracan√£", "Marapanim",
        "Medicil√¢ndia", "Melga√ßo", "Mocajuba", "Moju", "Monte Alegre", "Muan√°", "Nova Esperan√ßa do Piri√°",
        "Nova Ipixuna", "Nova Timboteua", "Novo Progresso", "Novo Repartimento", "√ìbidos",
        "Oeiras do Par√°", "Ourem", "Ouril√¢ndia do Norte", "Pacaj√°", "Palestina do Par√°",
        "Paragominas", "Pau D\"Arco", "Peixe-Boi", "Ponta de Pedras", "Portel", "Porto de Moz",
        "Primavera", "Quatipuru", "Reden√ß√£o", "Rio Maria", "Rondon do Par√°", "Rur√≥polis",
        "Salin√≥polis", "Santa B√°rbara do Par√°", "Santa Cruz do Arari", "Santa Izabel do Par√°",
        "Santa Luzia do Par√°", "Santa Maria das Barreiras", "Santa Maria do Par√°", "Santana do Araguaia",
        "Santar√©m Novo", "Santo Ant√¥nio do Tau√°", "S√£o Caetano de Odivelas", "S√£o Domingos do Araguaia",
        "S√£o Domingos do Capim", "S√£o Francisco do Par√°", "S√£o Geraldo do Araguaia",
        "S√£o Jo√£o da Ponta", "S√£o Jo√£o de Pirabas", "S√£o Jo√£o do Araguaia", "S√£o Miguel do Guam√°",
        "S√£o Sebasti√£o da Boa Vista", "Sapucaia", "Soure", "Tail√¢ndia", "Terra Alta", "Terra Santa",
        "Tom√©-A√ßu", "Tracuateua", "Trair√£o", "Tucum√£", "Tucuru√≠", "Ulian√≥polis", "Uruar√°",
        "Vigia", "Viseu", "Vit√≥ria do Xingu", "Xinguara"
    ]

    pss = "N/A"
    year = "N/A"

    pss_file_match = re.search(r'PSS(?:\s*N¬∫?)?(\s*\d{2}[-/]\d{4}|\s*\d{4})', filename, re.IGNORECASE)
    if pss_file_match:
        pss = pss_file_match.group(1).strip().replace('-', '/')
        if len(pss) == 4:
            pss = f"00/{pss}"

    # Tentar extrair PSS do texto
    if pss == "N/A":
        pss_text_match = re.search(r'PROCESSO SELETIVO SIMPLIFICADO N¬∫?\s*(\d{2}[-/]\d{4}|\d{4})', text, re.IGNORECASE)
        if pss_text_match:
            pss = pss_text_match.group(1).strip().replace('-', '/')
            if len(pss) == 4: 
                pss = f"00/{pss}"
        else:
            pss_text_match = re.search(r'PSS\s*N¬∫?\s*(\d{2}[-/]\d{4}|\d{4})', text, re.IGNORECASE)
            if pss_text_match:
                pss = pss_text_match.group(1).strip().replace('-', '/')
                if len(pss) == 4: 
                    pss = f"00/{pss}"

    year_file_match = re.search(r'(\d{4})', filename)
    if year_file_match:
        year = year_file_match.group(1)

    if year == "N/A":
        year_text_match = re.search(r'(\d{4})', text)
        if year_text_match:
            year = year_text_match.group(1)

    quadro_vagas_match = re.search(r'QUADRO DE VAGAS\s*(.*?)(?=(?:RELA√á√ÉO DE E-MAIL|TOTAL DE VAGAS|\Z))', text, re.DOTALL | re.IGNORECASE)
    
    if quadro_vagas_match:
        quadro_vagas_text = quadro_vagas_match.group(1)
        lines = quadro_vagas_text.split('\n')
        
        found_municipalities = []
        found_disciplines = []

        for line in lines:
            line = line.strip()
            if not line:
                continue

            for mun in municipios_comuns:
                if re.search(r'\b' + re.escape(mun) + r'\b', line, re.IGNORECASE):
                    found_municipalities.append(mun)

            for disc in disciplinas_comuns:
                if re.search(r'\b' + re.escape(disc) + r'\b', line, re.IGNORECASE):
                    found_disciplines.append(disc)

        found_municipalities = list(set(found_municipalities)) if found_municipalities else [None]
        found_disciplines = list(set(found_disciplines)) if found_disciplines else [None]

        for m in found_municipalities:
            for d in found_disciplines:
                data.append({
                    "Ano": year,
                    "PSS": pss,
                    "Edital": f"Edital n¬∫ {filename}",
                    "Munic√≠pio": m,
                    "Disciplina": d,
                    "Arquivo_Origem": filename,
                    "Data_Extra√ß√£o": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                })
    else:
        found_municipalities = []
        found_disciplines = []

        for mun in municipios_comuns:
            if re.search(r'\b' + re.escape(mun) + r'\b', text, re.IGNORECASE):
                found_municipalities.append(mun)
        
        for disc in disciplinas_comuns:
            if re.search(r'\b' + re.escape(disc) + r'\b', text, re.IGNORECASE):
                found_disciplines.append(disc)

        found_municipalities = list(set(found_municipalities)) if found_municipalities else [None]
        found_disciplines = list(set(found_disciplines)) if found_disciplines else [None]

        for m in found_municipalities:
            for d in found_disciplines:
                data.append({
                    "Ano": year,
                    "PSS": pss,
                    "Edital": f"Edital n¬∫ {filename}",
                    "Munic√≠pio": m,
                    "Disciplina": d,
                    "Arquivo_Origem": filename,
                    "Data_Extra√ß√£o": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                })

    return data

PASTA_PDFS = "C:/Users/SEDUC/Desktop/conv especiais"
ARQUIVO_SAIDA = "convocacoes_especiais.xlsx"

all_data = []

for arquivo in os.listdir(PASTA_PDFS):
    if not arquivo.lower().endswith(".pdf"):
        continue

    caminho = os.path.join(PASTA_PDFS, arquivo)
    print(f"üìÑ Processando PDF: {arquivo}")

    texto_pdf = extract_text_from_pdf(caminho)
    extracted_data = extract_info_from_text(texto_pdf, arquivo)
    
    if extracted_data:
        all_data.extend(extracted_data)
        print(f"‚úÖ {len(extracted_data)} dados extra√≠dos deste PDF.\n")
    else:
        print(f"‚ö†Ô∏è Nenhum dado extra√≠do deste PDF: {arquivo}.\n")

if all_data:
    df = pd.DataFrame(all_data)
    df.to_excel(ARQUIVO_SAIDA, index=False)
    print(f"üéâ Extra√ß√£o conclu√≠da! Dados salvos em {ARQUIVO_SAIDA}")
else:
    print("‚ùå Nenhuma informa√ß√£o extra√≠da de nenhum PDF.")